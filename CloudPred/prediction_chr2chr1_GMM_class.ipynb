{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbcb50e",
   "metadata": {},
   "source": [
    "#Prediction based on Linear SVM with average at sample level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbcadad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sklearn.model_selection as sks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rc_context\n",
    "import sklearn.metrics as skm\n",
    "from itertools import cycle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as clr\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random\n",
    "import collections\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "import math\n",
    "import scipy\n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "import logging.config\n",
    "import traceback\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "import numpy as np\n",
    "import sklearn.mixture\n",
    "import math\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6382565",
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2630e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Xtrain, centers=2,seed=0):\n",
    "    gm = collections.defaultdict(list)\n",
    "    count = collections.defaultdict(int)\n",
    "    for X, y, *_ in Xtrain:\n",
    "        gm[y].append(X)\n",
    "        count[y] += 1\n",
    "    \n",
    "    for state in gm:\n",
    "        gm[state] = np.concatenate(gm[state])\n",
    "        model = sklearn.mixture.GaussianMixture(centers,random_state=seed)\n",
    "        gm[state] = model.fit(gm[state])\n",
    "\n",
    "    return (gm, count)\n",
    "\n",
    "def eval(model, Xtest):\n",
    "    gm, count = model\n",
    "    total = 0.\n",
    "    correct = 0\n",
    "    prob = 0.\n",
    "    y_score = []\n",
    "    y_true = []\n",
    "    pred_=[]\n",
    "    for X, y, *_ in Xtest:\n",
    "        logp = {}\n",
    "        x = -float(\"inf\")\n",
    "        for state in gm:\n",
    "            logp[state] = sum(gm[state].score_samples(X))\n",
    "            x = max(x, logp[state])\n",
    "        y_score.append(logp[1] - logp[0])\n",
    "        y_true.append(y)\n",
    "        Z = 0\n",
    "        for state in logp:\n",
    "            logp[state] = math.exp(logp[state] - x) * count[state]\n",
    "            Z += logp[state]\n",
    "        pred = None\n",
    "        for state in logp:\n",
    "            logp[state] /= Z\n",
    "            if pred is None or logp[state] > logp[pred]:\n",
    "                pred = state\n",
    "        # total += math.log(logp[state])\n",
    "        pred_.append(pred)\n",
    "        correct += (pred == y)\n",
    "        prob += logp[y]\n",
    "    n = len(Xtest)\n",
    "\n",
    "    res = {}\n",
    "    res[\"accuracy\"] = correct / float(n)\n",
    "    res[\"soft\"] = prob / float(n)\n",
    "    res[\"auc\"] = sklearn.metrics.roc_auc_score(y_true, y_score)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    # logger.debug(\"        Generative Cross-entropy: \" + str(total / float(n)))\n",
    "    logger.debug(\"        Generative Accuracy:      \" + str(res[\"accuracy\"]))\n",
    "    logger.debug(\"        Generative Soft Accuracy: \" + str(res[\"soft\"]))\n",
    "    logger.debug(\"        Generative AUC:           \" + str(res[\"auc\"]))  \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c9659e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../2cohorts/chr2chr1/Xtest__.pkl\", \"rb\") as f:\n",
    "                Xtest = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Xall.pkl\", \"rb\") as f:\n",
    "                Xall = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Ctest__.pkl\", \"rb\") as f:\n",
    "                adata1_c = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Call__.pkl\", \"rb\") as f:\n",
    "                adata_c = pickle.load(f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "366bef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=np.concatenate([Xall[0],Xall[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfde0f8",
   "metadata": {},
   "source": [
    "## Load marker genes obtanined using seurat code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a970e1e",
   "metadata": {},
   "source": [
    "### Markers from the published paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "952f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markers = ['HLA-DRA','HLA-DRB1','LYZ','CST3','TYROBP','AP1S2','CSTA','FCN1','MS4A6A','LST1','CYBB','CTSS','DUSP6','IL1B','SGK1','KLF4','CLEC7A','ATP2B1-AS1','MARCKS',\n",
    "# 'SAT1','MYADM','IFI27','IFITM3','ISG15','APOBEC3A','IFI6','TNFSF10','MT2A','MX1','IFIT3','MNDA','S100A12','S100A9','S100A8','MAFB','VCAN','PLBD1','CXCL8',\n",
    "# 'RNASE2','FCGR3A','MS4A7','CDKN1C','AIF1','COTL1','FCER1G','C1QA','RHOC','FCGR3B','IFITM2','NAMPT','G0S2','PROK2','CMTM2',\n",
    "# 'BASP1','BCL2A1','SLC25A37','DEFA3','LTF','LCN2','CAMP','RETN','DEFA4','CD24','PGLYRP1','OLFM4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eededa36",
   "metadata": {},
   "source": [
    "# Input formating for the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ef41644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "            df= pd.read_csv('../scripts/marker_cohort2')\n",
    "            df[\"avg_log2FC\"] = np.abs(df[\"avg_log2FC\"])\n",
    "            df = df.loc[df[\"cluster\"].isin([7,11,3,4,6]),:]\n",
    "            feat_tab = df.groupby('cluster')\n",
    "            df2= feat_tab.apply(lambda x: x.sort_values([\"avg_log2FC\"], ascending=False)).reset_index(drop=True)\n",
    "            feat=df2.groupby('cluster').head(50)\n",
    "            idx_te= np.where(adata1_c.isin (feat.gene.values))[0] \n",
    "            idx_tr= np.where(adata_c.isin (adata1_c[idx_te]))[0]            \n",
    "\n",
    "#             markers = ['HLA-DRA','HLA-DRB1','LYZ','CST3','TYROBP','AP1S2','CSTA','FCN1','MS4A6A','LST1','CYBB','CTSS','DUSP6','IL1B','SGK1','KLF4','CLEC7A','ATP2B1-AS1','MARCKS','SAT1','MYADM','IFI27','IFITM3','ISG15','APOBEC3A','IFI6','TNFSF10','MT2A','MX1','IFIT3','MNDA','S100A12','S100A9','S100A8','MAFB','VCAN','PLBD1','CXCL8','RNASE2','FCGR3A','MS4A7','CDKN1C','AIF1','COTL1','FCER1G','C1QA','RHOC','FCGR3B','IFITM2','NAMPT','G0S2','PROK2','CMTM2','BASP1','BCL2A1','SLC25A37','DEFA3','LTF','LCN2','CAMP','RETN','DEFA4','CD24','PGLYRP1','OLFM4']\n",
    "#             idx_tr= np.where(adata_c.isin (markers))[0]\n",
    "#             idx_te= np.where(adata1_c.isin (markers))[0]\n",
    "\n",
    "            Xtrain = list(map(lambda x: (x[0][:,idx_tr], *x[1:]), Xtrain))\n",
    "            Xtest = list(map(lambda x: (x[0][:,idx_te], *x[1:]), Xtest))\n",
    "            Xtrain = list(map(lambda x: (x[0].todense(), *x[1:]), Xtrain))\n",
    "            Xtest  = list(map(lambda x: (x[0].todense(), *x[1:]), Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa34dc",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0751ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b56741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.72}\n",
      "{'accuracy': 0.7407407407407407, 'soft': 0.7407407407407407, 'auc': 0.8406593406593407}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.6, 'soft': 0.6, 'auc': 0.72}\n",
      "{'accuracy': 0.5925925925925926, 'soft': 0.5925925925925926, 'auc': 0.9725274725274726}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.5, 'soft': 0.5, 'auc': 0.625}\n",
      "{'accuracy': 0.7407407407407407, 'soft': 0.7407407407407407, 'auc': 0.8791208791208791}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.5714285714285714}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.967032967032967}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.8, 'soft': 0.8, 'auc': 0.8095238095238095}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.9395604395604397}\n"
     ]
    }
   ],
   "source": [
    "for seed in [0,42,10,1234,4321]:\n",
    "    print(\"start generative\")\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    for centers in [5]:\n",
    "                    kf = KFold(n_splits=5, shuffle= True, random_state=seed).split(X_train)\n",
    "                    for elem in kf:\n",
    "                        train_index, test_index=elem\n",
    "                        Xtrain, Xvalid = list(np.array(X_train)[train_index]), list(np.array(X_train)[test_index])\n",
    "                        print(len(Xvalid))\n",
    "                        model = train(Xtrain, centers,seed)\n",
    "                        logger.debug(\"    Training:\")\n",
    "                        res = eval(model, Xtrain)\n",
    "                        logger.debug(\"    Validation\")\n",
    "                        res = eval(model, Xvalid)\n",
    "\n",
    "                        if (res[\"accuracy\"] > best_score) or (res[\"accuracy\"] == best_score and res[\"auc\"] > best_score_auc):\n",
    "                            best_model = model\n",
    "                            best_score = res[\"accuracy\"]\n",
    "                            best_score_auc = res[\"auc\"]\n",
    "                            res_=res\n",
    "                            best_centers = centers\n",
    "\n",
    "    # with open(args.dir+'/generative', 'wb') as fp:\n",
    "    #                  pickle.dump(best_model, fp)             \n",
    "    print(res_)\n",
    "    res =eval(best_model, Xtest)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36613ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71b7de",
   "metadata": {},
   "source": [
    "### prediction on 25% of cohort2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ebf45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../2cohorts/chr2chr1/Xtest__.pkl\", \"rb\") as f:\n",
    "                Xtest = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Xall.pkl\", \"rb\") as f:\n",
    "                Xall = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Ctest__.pkl\", \"rb\") as f:\n",
    "                adata1_c = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Call__.pkl\", \"rb\") as f:\n",
    "                adata_c = pickle.load(f)\n",
    "                \n",
    "Xtrain=np.concatenate([Xall[0],Xall[1]])\n",
    "            \n",
    "df= pd.read_csv('../scripts/marker_cohort2')\n",
    "df[\"avg_log2FC\"] = np.abs(df[\"avg_log2FC\"])\n",
    "df = df.loc[df[\"cluster\"].isin([7,11,3,4,6]),:]\n",
    "feat_tab = df.groupby('cluster')\n",
    "df2= feat_tab.apply(lambda x: x.sort_values([\"avg_log2FC\"], ascending=False)).reset_index(drop=True)\n",
    "feat=df2.groupby('cluster').head(20)\n",
    "idx_te= np.where(adata1_c.isin (feat.gene.values))[0] \n",
    "idx_tr= np.where(adata_c.isin (adata1_c[idx_te]))[0]            \n",
    "\n",
    "#             markers = ['HLA-DRA','HLA-DRB1','LYZ','CST3','TYROBP','AP1S2','CSTA','FCN1','MS4A6A','LST1','CYBB','CTSS','DUSP6','IL1B','SGK1','KLF4','CLEC7A','ATP2B1-AS1','MARCKS','SAT1','MYADM','IFI27','IFITM3','ISG15','APOBEC3A','IFI6','TNFSF10','MT2A','MX1','IFIT3','MNDA','S100A12','S100A9','S100A8','MAFB','VCAN','PLBD1','CXCL8','RNASE2','FCGR3A','MS4A7','CDKN1C','AIF1','COTL1','FCER1G','C1QA','RHOC','FCGR3B','IFITM2','NAMPT','G0S2','PROK2','CMTM2','BASP1','BCL2A1','SLC25A37','DEFA3','LTF','LCN2','CAMP','RETN','DEFA4','CD24','PGLYRP1','OLFM4']\n",
    "#             idx_tr= np.where(adata_c.isin (markers))[0]\n",
    "#             idx_te= np.where(adata1_c.isin (markers))[0]\n",
    "\n",
    "Xtrain = list(map(lambda x: (x[0][:,idx_tr], *x[1:]), Xtrain))\n",
    "Xtest = list(map(lambda x: (x[0][:,idx_te], *x[1:]), Xtest))\n",
    "Xtrain = list(map(lambda x: (x[0].todense(), *x[1:]), Xtrain))\n",
    "Xtest  = list(map(lambda x: (x[0].todense(), *x[1:]), Xtest))\n",
    "X_train= Xtrain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce88e2",
   "metadata": {},
   "source": [
    "### Extract prediction at sample level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "05908790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 1.0}\n",
      "{'accuracy': 0.6296296296296297, 'soft': 0.6296296296296297, 'auc': 0.8681318681318682}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.6, 'soft': 0.6, 'auc': 0.6666666666666667}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.9615384615384616}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.6666666666666667}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.9615384615384616}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.7142857142857143}\n",
      "{'accuracy': 0.3333333333333333, 'soft': 0.3333333333333333, 'auc': 0.07692307692307691}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.8, 'soft': 0.8, 'auc': 0.875}\n",
      "{'accuracy': 0.3333333333333333, 'soft': 0.3333333333333333, 'auc': 0.0769230769230769}\n"
     ]
    }
   ],
   "source": [
    "for seed in [0,42,10,1234,4321]:\n",
    "    print(\"start generative\")\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    for centers in [5]:\n",
    "                    kf = KFold(n_splits=5, shuffle= True, random_state=seed).split(X_train)\n",
    "                    for elem in kf:\n",
    "                        train_index, test_index=elem\n",
    "                        Xtrain, Xvalid = list(np.array(X_train)[train_index]), list(np.array(X_train)[test_index])\n",
    "                        print(len(Xvalid))\n",
    "                        model = train(Xtrain, centers,seed)\n",
    "                        logger.debug(\"    Training:\")\n",
    "                        res = eval(model, Xtrain)\n",
    "                        logger.debug(\"    Validation\")\n",
    "                        res = eval(model, Xvalid)\n",
    "\n",
    "                        if (res[\"accuracy\"] > best_score) or (res[\"accuracy\"] == best_score and res[\"auc\"] > best_score_auc):\n",
    "                            best_model = model\n",
    "                            best_score = res[\"accuracy\"]\n",
    "                            best_score_auc = res[\"auc\"]\n",
    "                            res_=res\n",
    "                            best_centers = centers\n",
    "\n",
    "    # with open(args.dir+'/generative', 'wb') as fp:\n",
    "    #                  pickle.dump(best_model, fp)             \n",
    "    print(res_)\n",
    "    res =eval(best_model, Xtest)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab8093",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b015223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../2cohorts/chr2chr1/Xtest__.pkl\", \"rb\") as f:\n",
    "                Xtest = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Xall.pkl\", \"rb\") as f:\n",
    "                Xall = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Ctest__.pkl\", \"rb\") as f:\n",
    "                adata1_c = pickle.load(f)\n",
    "with open(\"../../2cohorts/chr2chr1/Call__.pkl\", \"rb\") as f:\n",
    "                adata_c = pickle.load(f)\n",
    "                \n",
    "Xtrain=np.concatenate([Xall[0],Xall[1]])\n",
    "            \n",
    "df= pd.read_csv('../scripts/marker_cohort2')\n",
    "df[\"avg_log2FC\"] = np.abs(df[\"avg_log2FC\"])\n",
    "df = df.loc[df[\"cluster\"].isin([7,11,3,4,6]),:]\n",
    "feat_tab = df.groupby('cluster')\n",
    "df2= feat_tab.apply(lambda x: x.sort_values([\"avg_log2FC\"], ascending=False)).reset_index(drop=True)\n",
    "feat=df2.groupby('cluster').head(100)\n",
    "idx_te= np.where(adata1_c.isin (feat.gene.values))[0] \n",
    "idx_tr= np.where(adata_c.isin (adata1_c[idx_te]))[0]            \n",
    "\n",
    "#             markers = ['HLA-DRA','HLA-DRB1','LYZ','CST3','TYROBP','AP1S2','CSTA','FCN1','MS4A6A','LST1','CYBB','CTSS','DUSP6','IL1B','SGK1','KLF4','CLEC7A','ATP2B1-AS1','MARCKS','SAT1','MYADM','IFI27','IFITM3','ISG15','APOBEC3A','IFI6','TNFSF10','MT2A','MX1','IFIT3','MNDA','S100A12','S100A9','S100A8','MAFB','VCAN','PLBD1','CXCL8','RNASE2','FCGR3A','MS4A7','CDKN1C','AIF1','COTL1','FCER1G','C1QA','RHOC','FCGR3B','IFITM2','NAMPT','G0S2','PROK2','CMTM2','BASP1','BCL2A1','SLC25A37','DEFA3','LTF','LCN2','CAMP','RETN','DEFA4','CD24','PGLYRP1','OLFM4']\n",
    "#             idx_tr= np.where(adata_c.isin (markers))[0]\n",
    "#             idx_te= np.where(adata1_c.isin (markers))[0]\n",
    "\n",
    "Xtrain = list(map(lambda x: (x[0][:,idx_tr], *x[1:]), Xtrain))\n",
    "Xtest = list(map(lambda x: (x[0][:,idx_te], *x[1:]), Xtest))\n",
    "Xtrain = list(map(lambda x: (x[0].todense(), *x[1:]), Xtrain))\n",
    "Xtest  = list(map(lambda x: (x[0].todense(), *x[1:]), Xtest))\n",
    "X_train= Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ddfb92fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.8, 'soft': 0.8, 'auc': 0.8095238095238095}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.44505494505494503}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.9, 'soft': 0.9, 'auc': 0.9600000000000001}\n",
      "{'accuracy': 0.5555555555555556, 'soft': 0.5555555555555556, 'auc': 0.45604395604395603}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.6, 'soft': 0.6, 'auc': 0.7083333333333334}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.6703296703296703}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.6, 'soft': 0.6, 'auc': 0.6666666666666667}\n",
      "{'accuracy': 0.5185185185185185, 'soft': 0.5185185185185185, 'auc': 0.9505494505494505}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.7083333333333334}\n",
      "{'accuracy': 0.37037037037037035, 'soft': 0.37037037037037035, 'auc': 0.1978021978021978}\n"
     ]
    }
   ],
   "source": [
    "for seed in [0,42,10,1234,4321]:\n",
    "    print(\"start generative\")\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    for centers in [5]:\n",
    "                    kf = KFold(n_splits=5, shuffle= True, random_state=seed).split(X_train)\n",
    "                    for elem in kf:\n",
    "                        train_index, test_index=elem\n",
    "                        Xtrain, Xvalid = list(np.array(X_train)[train_index]), list(np.array(X_train)[test_index])\n",
    "                        print(len(Xvalid))\n",
    "                        model = train(Xtrain, centers,seed)\n",
    "                        logger.debug(\"    Training:\")\n",
    "                        res = eval(model, Xtrain)\n",
    "                        logger.debug(\"    Validation\")\n",
    "                        res = eval(model, Xvalid)\n",
    "\n",
    "                        if (res[\"accuracy\"] > best_score) or (res[\"accuracy\"] == best_score and res[\"auc\"] > best_score_auc):\n",
    "                            best_model = model\n",
    "                            best_score = res[\"accuracy\"]\n",
    "                            best_score_auc = res[\"auc\"]\n",
    "                            res_=res\n",
    "                            best_centers = centers\n",
    "\n",
    "    # with open(args.dir+'/generative', 'wb') as fp:\n",
    "    #                  pickle.dump(best_model, fp)             \n",
    "    print(res_)\n",
    "    res =eval(best_model, Xtest)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40ba26",
   "metadata": {},
   "source": [
    "# Test on Cohort1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262229b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../2cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2f2abac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../2cohorts_markers/chr2chr1/Xtest__.pkl\", \"rb\") as f:\n",
    "                Xtest = pickle.load(f)\n",
    "with open(\"../../2cohorts_markers/chr2chr1/Xall.pkl\", \"rb\") as f:\n",
    "                Xall = pickle.load(f)\n",
    "with open(\"../../2cohorts_markers/chr2chr1/Ctest__.pkl\", \"rb\") as f:\n",
    "                adata1_c = pickle.load(f)\n",
    "with open(\"../../2cohorts_markers/chr2chr1/Call__.pkl\", \"rb\") as f:\n",
    "                adata_c = pickle.load(f)\n",
    "                \n",
    "Xtrain=np.concatenate([Xall[0],Xall[1]])\n",
    "            \n",
    "df= pd.read_csv('../scripts/marker_cohort2')\n",
    "df[\"avg_log2FC\"] = np.abs(df[\"avg_log2FC\"])\n",
    "# df = df.loc[df[\"cluster\"].isin([7,11,3,4,6]),:]\n",
    "feat_tab = df.groupby('cluster')\n",
    "df2= feat_tab.apply(lambda x: x.sort_values([\"avg_log2FC\"], ascending=False)).reset_index(drop=True)\n",
    "feat=df2.groupby('cluster').head(20)\n",
    "idx_te= np.where(adata1_c.isin (feat.gene.values))[0] \n",
    "idx_tr= np.where(adata_c.isin (adata1_c[idx_te]))[0]            \n",
    "\n",
    "#             markers = ['HLA-DRA','HLA-DRB1','LYZ','CST3','TYROBP','AP1S2','CSTA','FCN1','MS4A6A','LST1','CYBB','CTSS','DUSP6','IL1B','SGK1','KLF4','CLEC7A','ATP2B1-AS1','MARCKS','SAT1','MYADM','IFI27','IFITM3','ISG15','APOBEC3A','IFI6','TNFSF10','MT2A','MX1','IFIT3','MNDA','S100A12','S100A9','S100A8','MAFB','VCAN','PLBD1','CXCL8','RNASE2','FCGR3A','MS4A7','CDKN1C','AIF1','COTL1','FCER1G','C1QA','RHOC','FCGR3B','IFITM2','NAMPT','G0S2','PROK2','CMTM2','BASP1','BCL2A1','SLC25A37','DEFA3','LTF','LCN2','CAMP','RETN','DEFA4','CD24','PGLYRP1','OLFM4']\n",
    "#             idx_tr= np.where(adata_c.isin (markers))[0]\n",
    "#             idx_te= np.where(adata1_c.isin (markers))[0]\n",
    "\n",
    "Xtrain = list(map(lambda x: (x[0][:,idx_tr], *x[1:]), Xtrain))\n",
    "Xtest = list(map(lambda x: (x[0][:,idx_te], *x[1:]), Xtest))\n",
    "Xtrain = list(map(lambda x: (x[0].todense(), *x[1:]), Xtrain))\n",
    "Xtest  = list(map(lambda x: (x[0].todense(), *x[1:]), Xtest))\n",
    "X_train= Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "69a0cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.9, 'soft': 0.9, 'auc': 0.8400000000000001}\n",
      "{'accuracy': 0.8518518518518519, 'soft': 0.8518518518518519, 'auc': 0.956043956043956}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.9, 'soft': 0.9, 'auc': 0.9600000000000001}\n",
      "{'accuracy': 0.48148148148148145, 'soft': 0.48148148148148145, 'auc': 0.04945054945054943}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.8, 'soft': 0.8, 'auc': 0.9166666666666666}\n",
      "{'accuracy': 0.48148148148148145, 'soft': 0.48148148148148145, 'auc': 0.4175824175824175}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.8, 'soft': 0.8, 'auc': 0.8571428571428572}\n",
      "{'accuracy': 0.48148148148148145, 'soft': 0.48148148148148145, 'auc': 0.48351648351648346}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.9, 'soft': 0.9, 'auc': 1.0}\n",
      "{'accuracy': 0.48148148148148145, 'soft': 0.48148148148148145, 'auc': 0.3626373626373626}\n"
     ]
    }
   ],
   "source": [
    "for seed in [0,42,10,1234,4321]:\n",
    "    print(\"start generative\")\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    for centers in [5]:\n",
    "                    kf = KFold(n_splits=5, shuffle= True, random_state=seed).split(X_train)\n",
    "                    for elem in kf:\n",
    "                        train_index, test_index=elem\n",
    "                        Xtrain, Xvalid = list(np.array(X_train)[train_index]), list(np.array(X_train)[test_index])\n",
    "                        print(len(Xvalid))\n",
    "                        model = train(Xtrain, centers,seed)\n",
    "                        logger.debug(\"    Training:\")\n",
    "                        res = eval(model, Xtrain)\n",
    "                        logger.debug(\"    Validation\")\n",
    "                        res = eval(model, Xvalid)\n",
    "\n",
    "                        if (res[\"accuracy\"] > best_score) or (res[\"accuracy\"] == best_score and res[\"auc\"] > best_score_auc):\n",
    "                            best_model = model\n",
    "                            best_score = res[\"accuracy\"]\n",
    "                            best_score_auc = res[\"auc\"]\n",
    "                            res_=res\n",
    "                            best_centers = centers\n",
    "\n",
    "    # with open(args.dir+'/generative', 'wb') as fp:\n",
    "    #                  pickle.dump(best_model, fp)             \n",
    "    print(res_)\n",
    "    res =eval(best_model, Xtest)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a979baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "{'accuracy': 0.7, 'soft': 0.7, 'auc': 0.8}\n",
      "{'accuracy': 0.48148148148148145, 'soft': 0.48148148148148145, 'auc': 0.3956043956043956}\n",
      "start generative\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for seed in [0,42,10,1234,4321]:\n",
    "    print(\"start generative\")\n",
    "    best_model = None\n",
    "    best_score = -float(\"inf\")\n",
    "    for centers in [21]:\n",
    "                    kf = KFold(n_splits=5, shuffle= True, random_state=seed).split(X_train)\n",
    "                    for elem in kf:\n",
    "                        train_index, test_index=elem\n",
    "                        Xtrain, Xvalid = list(np.array(X_train)[train_index]), list(np.array(X_train)[test_index])\n",
    "                        print(len(Xvalid))\n",
    "                        model = train(Xtrain, centers,seed)\n",
    "                        logger.debug(\"    Training:\")\n",
    "                        res = eval(model, Xtrain)\n",
    "                        logger.debug(\"    Validation\")\n",
    "                        res = eval(model, Xvalid)\n",
    "\n",
    "                        if (res[\"accuracy\"] > best_score) or (res[\"accuracy\"] == best_score and res[\"auc\"] > best_score_auc):\n",
    "                            best_model = model\n",
    "                            best_score = res[\"accuracy\"]\n",
    "                            best_score_auc = res[\"auc\"]\n",
    "                            res_=res\n",
    "                            best_centers = centers\n",
    "\n",
    "    # with open(args.dir+'/generative', 'wb') as fp:\n",
    "    #                  pickle.dump(best_model, fp)             \n",
    "    print(res_)\n",
    "    res =eval(best_model, Xtest)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ab259b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    classes_=[0,1]\n",
    "    fpr, tpr, _ = skm.roc_curve(y_t2,  pred_agg2)\n",
    "    auc = skm.roc_auc_score(y_t2,  pred_agg2)\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa712c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
